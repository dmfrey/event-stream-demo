
logging:
  level:
    org.apache.kafka: INFO
    org.apache.kafka.streams: INFO
    org.springframework.cloud: DEBUG
    org.springframework.cloud.stream: DEBUG
    org.springframework.web: DEBUG
    io.pivotal.dmfrey: DEBUG

node:
  current: local
  available: local, cloud, node-17, node-34

spring:

  jackson:
    serialization:
      write_dates_as_timestamps: false

  cloud:
    stream:
      function:
        definition: workorderEventsTableTransformer
      source: workorder-events
      bindings:
        workorder-events-out-0:
          destination: ${node.current}.workorder-events
#          contentType: application/json
#          producer:
#            headerMode: headers
#        workorderEventsTableTransformer-in-0:
#          destination: ${node.current}.workorder-events
#          group: workorder-events-stream
#          contentType: application/json
#          consumer:
#            headerMode: headers
      kafka:
        binder:
          brokers: ["localhost:9092"]
        streams:
          binder:
            configuration:
              commit.interval.ms: 1000
          bindings:
            workorder-events-out-0:
              producer:
                keySerde: org.apache.kafka.common.serialization.Serdes.UUIDSerde
                valueSerde: org.springframework.kafka.support.serializer.JsonSerde
#            workorderEventsTableTransformer-in-0:
#              consumer.application-id: ${node.current}.event-stream-demo.transformer
            workorder-events-by-id:
              consumer:
                materializedAs: ${node.current}.workorder-events-by-id

#Actuator
management:
  endpoints:
    web.exposure.include: "*"
  endpoint:
    health:
      show-details: ALWAYS
    restart:
      enabled: true
